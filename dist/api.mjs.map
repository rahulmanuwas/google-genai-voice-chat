{"version":3,"sources":["../src/api/createChatHandler.ts"],"names":[],"mappings":";;;AAgCO,SAAS,kBAAkB,MAAA,EAA2B;AACzD,EAAA,MAAM,EAAE,YAAA,EAAc,KAAA,GAAQ,kBAAA,EAAoB,mBAAA,GAAsB,mCAAkC,GAAI,MAAA;AAE9G,EAAA,OAAO,eAAe,QAAQ,OAAA,EAAqC;AAC/D,IAAA,IAAI;AACA,MAAA,MAAM,MAAA,GAAS,QAAQ,GAAA,CAAI,cAAA;AAC3B,MAAA,IAAI,CAAC,MAAA,EAAQ;AACT,QAAA,OAAO,QAAA,CAAS,IAAA;AAAA,UACZ,EAAE,OAAO,wBAAA,EAAyB;AAAA,UAClC,EAAE,QAAQ,GAAA;AAAI,SAClB;AAAA,MACJ;AAEA,MAAA,MAAM,IAAA,GAAO,MAAM,OAAA,CAAQ,IAAA,EAAK;AAChC,MAAA,MAAM,EAAE,OAAA,EAAS,OAAA,EAAQ,GAAI,IAAA;AAE7B,MAAA,IAAI,CAAC,OAAA,IAAW,OAAO,OAAA,KAAY,QAAA,EAAU;AACzC,QAAA,OAAO,QAAA,CAAS,IAAA;AAAA,UACZ,EAAE,OAAO,qBAAA,EAAsB;AAAA,UAC/B,EAAE,QAAQ,GAAA;AAAI,SAClB;AAAA,MACJ;AAEA,MAAA,MAAM,EAAA,GAAK,IAAI,WAAA,CAAY,EAAE,QAAQ,CAAA;AAErC,MAAA,MAAM,QAAA,GAAW;AAAA,QACb,EAAE,MAAM,MAAA,EAAiB,KAAA,EAAO,CAAC,EAAE,IAAA,EAAM,YAAA,EAAc,CAAA,EAAE;AAAA,QACzD,EAAE,MAAM,OAAA,EAAkB,KAAA,EAAO,CAAC,EAAE,IAAA,EAAM,mBAAA,EAAqB,CAAA;AAAE,OACrE;AAEA,MAAA,IAAI,KAAA,CAAM,OAAA,CAAQ,OAAO,CAAA,EAAG;AACxB,QAAA,KAAA,MAAW,OAAO,OAAA,EAAS;AACvB,UAAA,QAAA,CAAS,IAAA,CAAK;AAAA,YACV,IAAA,EAAM,GAAA,CAAI,IAAA,KAAS,MAAA,GAAS,MAAA,GAAkB,OAAA;AAAA,YAC9C,OAAO,CAAC,EAAE,IAAA,EAAM,GAAA,CAAI,SAAS;AAAA,WAChC,CAAA;AAAA,QACL;AAAA,MACJ;AAEA,MAAA,QAAA,CAAS,IAAA,CAAK,EAAE,IAAA,EAAM,MAAA,EAAiB,KAAA,EAAO,CAAC,EAAE,IAAA,EAAM,OAAA,EAAS,CAAA,EAAG,CAAA;AAEnE,MAAA,MAAM,QAAA,GAAW,MAAM,EAAA,CAAG,MAAA,CAAO,eAAA,CAAgB;AAAA,QAC7C,KAAA;AAAA,QACA;AAAA,OACH,CAAA;AAED,MAAA,MAAM,IAAA,GAAO,SAAS,IAAA,IAAQ,oEAAA;AAE9B,MAAA,OAAO,QAAA,CAAS,IAAA,CAAK,EAAE,QAAA,EAAU,MAAsB,CAAA;AAAA,IAC3D,SAAS,KAAA,EAAO;AACZ,MAAA,OAAA,CAAQ,KAAA,CAAM,mBAAmB,KAAK,CAAA;AACtC,MAAA,OAAO,QAAA,CAAS,IAAA;AAAA,QACZ,EAAE,OAAO,2BAAA,EAA4B;AAAA,QACrC,EAAE,QAAQ,GAAA;AAAI,OAClB;AAAA,IACJ;AAAA,EACJ,CAAA;AACJ","file":"api.mjs","sourcesContent":["// src/api/createChatHandler.ts\n\n/**\n * Factory function to create a Next.js API route handler for text-only chat\n */\n\nimport { GoogleGenAI } from '@google/genai';\nimport type { ChatHandlerConfig } from '../lib/types';\n\ninterface ChatRequest {\n    message: string;\n    history?: Array<{ role: 'user' | 'model'; content: string }>;\n}\n\ninterface ChatResponse {\n    response?: string;\n    error?: string;\n}\n\n/**\n * Create a chat handler for Next.js API routes\n * \n * @example\n * ```ts\n * // app/api/chat/route.ts\n * import { createChatHandler } from 'google-genai-voice-chat/api';\n * \n * export const POST = createChatHandler({\n *   systemPrompt: 'You are a helpful assistant...',\n * });\n * ```\n */\nexport function createChatHandler(config: ChatHandlerConfig) {\n    const { systemPrompt, model = 'gemini-2.0-flash', modelAcknowledgment = 'Understood. I am ready to help.' } = config;\n\n    return async function handler(request: Request): Promise<Response> {\n        try {\n            const apiKey = process.env.GEMINI_API_KEY;\n            if (!apiKey) {\n                return Response.json(\n                    { error: 'API key not configured' } as ChatResponse,\n                    { status: 500 }\n                );\n            }\n\n            const body = await request.json() as ChatRequest;\n            const { message, history } = body;\n\n            if (!message || typeof message !== 'string') {\n                return Response.json(\n                    { error: 'Message is required' } as ChatResponse,\n                    { status: 400 }\n                );\n            }\n\n            const ai = new GoogleGenAI({ apiKey });\n\n            const contents = [\n                { role: 'user' as const, parts: [{ text: systemPrompt }] },\n                { role: 'model' as const, parts: [{ text: modelAcknowledgment }] },\n            ];\n\n            if (Array.isArray(history)) {\n                for (const msg of history) {\n                    contents.push({\n                        role: msg.role === 'user' ? 'user' as const : 'model' as const,\n                        parts: [{ text: msg.content }],\n                    });\n                }\n            }\n\n            contents.push({ role: 'user' as const, parts: [{ text: message }] });\n\n            const response = await ai.models.generateContent({\n                model,\n                contents,\n            });\n\n            const text = response.text || \"I apologize, but I couldn't generate a response. Please try again.\";\n\n            return Response.json({ response: text } as ChatResponse);\n        } catch (error) {\n            console.error('Chat API error:', error);\n            return Response.json(\n                { error: 'Failed to process request' } as ChatResponse,\n                { status: 500 }\n            );\n        }\n    };\n}\n"]}